#!/bin/bash
# download-docs.sh - Download all documentation from llm.txt
# Makes ProzessÃ¼bersicht documentation available offline for AI agents

set -e

OUTPUT_DIR="maco-api-documentation/docs-offline"
INDEX_FILE="$OUTPUT_DIR/index.json"

echo "ğŸ“¥ Downloading MaCo API Documentation..."
echo "Output directory: $OUTPUT_DIR"
mkdir -p "$OUTPUT_DIR"

# Extract all doc.macoapp.de URLs from llm.txt
echo "Extracting URLs from llm.txt..."
URLS=$(grep -o 'https://doc\.macoapp\.de/[^)]*' llm.txt | sort -u)

URL_COUNT=$(echo "$URLS" | wc -l | tr -d ' ')
echo "Found $URL_COUNT unique documentation URLs"

# Create index structure
echo "{" > "$INDEX_FILE"
FIRST=true

SUCCESS_COUNT=0
FAIL_COUNT=0

while IFS= read -r url; do
    if [ -z "$url" ]; then
        continue
    fi
    
    # Extract filename from URL
    filename=$(basename "$url")
    # Decode URL encoding (basic)
    filename=$(echo "$filename" | sed 's/%C3%BC/Ã¼/g' | sed 's/%C3%A4/Ã¤/g' | sed 's/%C3%B6/Ã¶/g' | sed 's/%C3%9C/Ãœ/g' | sed 's/%C3%84/Ã„/g' | sed 's/%C3%96/Ã–/g' | sed 's/%C3%9F/ÃŸ/g')
    
    output_path="$OUTPUT_DIR/$filename"
    
    # Download the file
    if curl -s -f -L "$url" -o "$output_path" --max-time 30; then
        echo "âœ… Downloaded: $filename"
        SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
        
        # Add to index
        if [ "$FIRST" = false ]; then
            echo "," >> "$INDEX_FILE"
        fi
        echo "  \"$filename\": \"$url\"" | tr -d '\n' >> "$INDEX_FILE"
        FIRST=false
    else
        echo "âŒ Failed: $filename"
        FAIL_COUNT=$((FAIL_COUNT + 1))
    fi
    
    # Small delay to be respectful
    sleep 0.5
done <<< "$URLS"

echo "}" >> "$INDEX_FILE"

echo ""
echo "ğŸ“Š Summary:"
echo "  âœ… Successfully downloaded: $SUCCESS_COUNT"
echo "  âŒ Failed: $FAIL_COUNT"
echo "  ğŸ“ Files saved to: $OUTPUT_DIR"
echo "  ğŸ“‹ Index created: $INDEX_FILE"

